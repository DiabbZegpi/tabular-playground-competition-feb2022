---
title: "01_data_exploration"
author: "Diabb Zegpi"
date: "15-02-2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(here)

bacteria <- read_csv(here("Data", "train.csv"))
# bacteria_test <- read_csv(here("Data", "test.csv"))
```

```{r}
bacteria %>% count(target, sort = TRUE)
```

There are 10 targets in total in a well balanced manner. Lets calculate a benchmark accuracy.

```{r}
set.seed(111)
benchmark_sample <- sample(unique(bacteria$target), 
                           size = 2e5, 
                           replace = TRUE)

mean(bacteria$target == benchmark_sample)
```

A priori, the benchmark accuracy is approximately 10%. 

## Preprocessing with normalize, filter with correlations and apply PCA

```{r}
library(tidymodels)
set.seed(112)
splits <- initial_split(bacteria)
bacteria_train <- training(splits)
bacteria_test <- testing(splits)

set.seed(113)
folds <- vfold_cv(bacteria_train)

preprocessing <- recipe(target ~ ., data = bacteria_train) %>% 
  update_role(row_id, new_role = "id") %>% 
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_corr(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors())
```

## Model specs

```{r}
svm_spec <- svm_poly(degree = 2) %>% 
  set_mode("classification") %>% 
  set_engine("kernlab")

nnet_spec <- multinom_reg(penalty = .001, mixture = 1) %>% 
  set_mode("classification") %>% 
  set_engine("nnet")

knn_spec <- nearest_neighbor(neighbors = 10) %>% 
  set_mode("classification") %>% 
  set_engine("kknn")

rf_spec <- rand_forest(trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

xgb_spec <- boost_tree(trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost")
```

## Workflows

```{r}
svm_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(svm_spec)

nnet_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(nnet_spec)

knn_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(knn_spec)

rf_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(rf_spec)

xgb_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(xgb_spec)
```


## Fit resamples


```{r}
# library(doParallel)
# cores <- parallel::detectCores() - 1
# cl <- makePSOCKcluster(cores)
# registerDoParallel(cl)

# SVM accuracy = 0.737
# svm_res <- fit_resamples(
#   svm_wf, 
#   resamples = folds, 
#   metrics = metric_set(accuracy),
#   control = control_resamples(verbose = TRUE)
# )

# NNET accuracy = 0.669
# nnet_res <- fit_resamples(
#   nnet_wf,
#   resamples = folds,
#   metrics = metric_set(accuracy),
#   control = control_resamples(verbose = TRUE)
# )

# KNN accuracy = 0.924
# knn_res <- fit_resamples(
#   knn_wf,
#   resamples = folds,
#   metrics = metric_set(accuracy),
#   control = control_resamples(verbose = TRUE)
# )

# Random Forest accuracy = 0.975
# rf_res <- fit_resamples(
#   rf_wf,
#   resamples = folds,
#   metrics = metric_set(accuracy),
#   control = control_resamples(verbose = TRUE)
# )

# XGBoost accuracy = 0.976
# gbm_res <- fit_resamples(
#   xgb_wf,
#   resamples = folds,
#   metrics = metric_set(accuracy),
#   control = control_resamples(verbose = TRUE)
# )
```


The two best models are: random forest and XGBoost, both with 1000 trees. The next step is make an initial submission with models trained in whole dataset. Then, hyperparameter tuning baby!

## Training in the whole dataset

```{r}
library(doParallel)

cores <- detectCores() - 1
cluster <- makeCluster(cores)
registerDoParallel(cluster)

t0 <- Sys.time()
rf_fit <- fit(rf_wf, data = bacteria_train)
t1 <- Sys.time()
beepr::beep(4)
stopImplicitCluster()
```

```{r}
registerDoParallel(cluster)

t0 <- Sys.time()
xgb_fit <- fit(xgb_wf, data = bacteria_train)
t1 <- Sys.time()
beepr::beep(4)
stopImplicitCluster()
```

```{r}
train_predictions <- tibble(
  rf_preds = predict(rf_fit, new_data = bacteria_train) 
) %>%
  bind_cols(
    xgb_preds = predict(xgb_fit, new_data = bacteria_train)
  ) %>% 
  bind_cols(target = bacteria_train$target)
```

```{r}
train_predictions
```
















